# N8N AI Starter Kit - Environment Schema
# This file defines all environment variables used in the project
# Copy template.env to .env and modify values as needed

# =============================================================================
# CORE SERVICES CONFIGURATION
# =============================================================================

# N8N Configuration
N8N_HOST=string                    # N8N service hostname (default: localhost)
N8N_PORT=number                    # N8N service port (default: 5678)
N8N_PROTOCOL=string               # Protocol for N8N access (http/https)
N8N_DOMAIN=string                 # Full domain for N8N service
N8N_PERSONAL_ACCESS_TOKEN=string  # N8N Personal Access Token for API
N8N_API_KEY=string               # N8N Public API Key (alternative to PAT)

# Database Configuration - PostgreSQL
POSTGRES_HOST=string              # PostgreSQL hostname
POSTGRES_PORT=number              # PostgreSQL port (default: 5432)
POSTGRES_DB=string               # Database name
POSTGRES_USER=string             # Database user
POSTGRES_PASSWORD=string         # Database password (MUST be secure)

# Vector Database - Qdrant
QDRANT_HOST=string               # Qdrant hostname
QDRANT_PORT=number               # Qdrant port (default: 6333)
QDRANT_API_KEY=string           # Qdrant API key for authentication

# =============================================================================
# MONITORING & OBSERVABILITY
# =============================================================================

# Grafana Configuration
GRAFANA_HOST=string              # Grafana hostname
GRAFANA_PORT=number              # Grafana port (default: 3000)
GRAFANA_ADMIN_USER=string       # Grafana admin username
GRAFANA_ADMIN_PASSWORD=string   # Grafana admin password
GRAFANA_DOMAIN=string           # Full domain for Grafana service

# Prometheus Configuration
PROMETHEUS_PORT=number           # Prometheus port (default: 9090)

# =============================================================================
# DOMAIN & TLS CONFIGURATION
# =============================================================================

# Domain Settings
DOMAIN=string                    # Base domain name
API_DOMAIN=string               # API service domain

# TLS/ACME Configuration  
ACME_EMAIL=string               # Email for Let's Encrypt certificates
TRAEFIK_LOG_LEVEL=string       # Traefik log level (INFO, DEBUG, ERROR)

# Traefik Dashboard Credentials
TRAEFIK_DASHBOARD_USER=string   # Traefik dashboard username (default: admin)
TRAEFIK_DASHBOARD_PASSWORD=string # Traefik dashboard password (MUST be secure)
TRAEFIK_DASHBOARD_HASHED_PASSWORD=string # Hashed password for Traefik basic auth

# =============================================================================
# FASTAPI SERVICES CONFIGURATION
# =============================================================================

# Web Interface Service
WEB_INTERFACE_PORT=number       # Web interface port (default: 8000)
WEB_INTERFACE_WORKERS=number    # Number of workers (default: 1)

# Document Processor Service
DOC_PROCESSOR_PORT=number       # Document processor port (default: 8001)
DOC_PROCESSOR_WORKERS=number    # Number of workers (default: 1)
DOC_PROCESSOR_MODEL=string      # SentenceTransformers model name

# ETL Processor Service
ETL_PROCESSOR_PORT=number       # ETL processor port (default: 8002)
ETL_PROCESSOR_WORKERS=number    # Number of workers (default: 1)

# LightRAG Service
LIGHTRAG_PORT=number           # LightRAG service port (default: 8003)
LIGHTRAG_WORKERS=number        # Number of workers (default: 1)
LIGHTRAG_WORKING_DIR=string    # Working directory for LightRAG data (default: /app/data/lightrag)
LIGHTRAG_LLM_MODEL=string      # LLM model for LightRAG (gpt-4o-mini, gpt-4o)
LIGHTRAG_EMBEDDING_MODEL=string # Embedding model (text-embedding-3-small)
LIGHTRAG_MAX_TOKENS=number     # Max tokens for LLM responses (default: 32768)
LIGHTRAG_CHUNK_SIZE=number     # Document chunk size (default: 1200)
LIGHTRAG_OVERLAP_SIZE=number   # Chunk overlap size (default: 100)
OPENAI_API_KEY=string          # OpenAI API key for LightRAG
OPENAI_API_BASE=string         # OpenAI API base URL (optional)

# Model Provider Selection
USE_LOCAL_MODELS=boolean       # Use local models instead of OpenAI (default: false)
MODEL_PROVIDER=string          # Model provider: openai, ollama (default: openai)

# =============================================================================
# OPTIONAL ANALYTICS SERVICES
# =============================================================================

# ClickHouse Configuration (analytics profile)
CLICKHOUSE_HOST=string          # ClickHouse hostname
CLICKHOUSE_PORT=number          # ClickHouse HTTP port (default: 8123)
CLICKHOUSE_USER=string          # ClickHouse user
CLICKHOUSE_PASSWORD=string      # ClickHouse password

# =============================================================================
# DOCKER COMPOSE CONFIGURATION
# =============================================================================

# Compose Profiles
COMPOSE_PROFILES=string         # Active compose profiles (comma-separated)
                               # Available: default,developer,monitoring,analytics,gpu

# =============================================================================
# GPU CONFIGURATION (gpu profile)
# =============================================================================

# GPU Hardware Settings
GPU_TYPE=string                 # GPU type (nvidia, amd, auto)
CUDA_VISIBLE_DEVICES=string     # CUDA device IDs (0,1,2... or all)
ROCR_VISIBLE_DEVICES=string     # ROCm device IDs for AMD GPUs

# GPU Service Ports
DOC_PROCESSOR_GPU_PORT=number   # Document processor GPU port (default: 8011)
LIGHTRAG_GPU_PORT=number        # LightRAG GPU port (default: 8013)
GPU_MONITOR_PORT=number         # GPU monitor port (default: 8014)

# GPU Service Configuration
DOC_PROCESSOR_GPU_WORKERS=number # Document processor GPU workers (default: 1)
LIGHTRAG_GPU_WORKERS=number      # LightRAG GPU workers (default: 1)

# Local AI Models (for GPU services)
LIGHTRAG_GPU_LLM_MODEL=string    # Local LLM model name or path
LIGHTRAG_GPU_EMBEDDING_MODEL=string # Local embedding model name
MODEL_CACHE_DIR=string           # Local directory for model caching

# GPU Memory Management
GPU_MEMORY_FRACTION=number       # GPU memory fraction to use (0.1-1.0)
MAX_GPU_MEMORY_MB=number         # Maximum GPU memory in MB

# =============================================================================
# OLLAMA CONFIGURATION (gpu profile)
# =============================================================================

# Ollama Server Settings
OLLAMA_HOST=string               # Ollama server host (default: ollama)
OLLAMA_PORT=number               # Ollama server port (default: 11434)
OLLAMA_BASE_URL=string           # Full Ollama API base URL

# Model Management
OLLAMA_DEFAULT_MODEL=string      # Default Ollama model (e.g., llama2, mistral)
OLLAMA_EMBEDDING_MODEL=string    # Ollama embedding model
OLLAMA_PULL_TIMEOUT=number       # Model download timeout in seconds

# Performance Settings
OLLAMA_NUM_PARALLEL=number       # Number of parallel requests
OLLAMA_NUM_CTX=number           # Context window size
OLLAMA_NUM_PREDICT=number       # Max tokens to predict
OLLAMA_TEMPERATURE=number       # Model temperature (0.0-2.0)
OLLAMA_TOP_K=number             # Top-K sampling
OLLAMA_TOP_P=number             # Top-P sampling

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================

# Debug & Development
DEBUG=boolean                   # Enable debug mode (true/false)
LOG_LEVEL=string               # Application log level (INFO, DEBUG, ERROR)

# =============================================================================
# SUPABASE CONFIGURATION (Hybrid Approach)
# =============================================================================

# Supabase Connection Settings
SUPABASE_URL=string             # Supabase project URL (e.g., https://your-project.supabase.co)
SUPABASE_KEY=string             # Supabase API key (anon or service key)
SUPABASE_SCHEMA=string          # Database schema to use (default: public)

# Supabase AI/Analytics Tables
SUPABASE_AI_TABLE=string        # Table for AI processing results (default: ai_results)
SUPABASE_EMBEDDINGS_TABLE=string # Table for document embeddings (default: document_embeddings)
SUPABASE_ANALYTICS_TABLE=string # Table for analytics data (default: ai_analytics)

# =============================================================================
# SECURITY NOTES
# =============================================================================
# - Never commit .env files to version control
# - Use strong passwords (min 20 characters, mixed case, numbers, symbols)
# - Rotate credentials regularly
# - Use different credentials for development and production
# - Consider using external secret management for production deployments